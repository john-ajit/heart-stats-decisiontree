{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## A Data-Driven Approach to Public Health: Improving the Prevention and Management of Heart Disease and the Importance of Non-Invasive Measures\n",
    "Nate Dorsey, John Ajit\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Abstract\n",
    "\n",
    "Heart disease has been the leading cause of death in the United States since 1950. Today, heart disease is responsible for nearly 30% of all deaths in the states. The use of non-invasive measures for early detection of heart disease in patients is crucial for patient well-being, efficacy of medical intervention and treatment in the prevention and management of heart disease, accessibility of care, and the health and efficiency of the healthcare system as a whole. Through a data-driven approach, we were able to assess the efficacy of various non-invasive measures in detecting heart disease.\n",
    "\n",
    "Overall, patients for whom early detection and intervention was utilized saw a 5-year survival rate as high as 90%, compared to 50% in patients with late-stage diagnoses, a reduction in hospitalization by about 30%, and a decrease in mortality rates by upwards of 20-25%. Early detection followed by timely medical intervention can be the deciding factor in survival rates, rates of hospitalization, and overall mortality rates of patients.\n",
    "\n",
    "Non-invasive measures are largely used for early detection, and for good reason. They are low risk, cost-effective to both the individual and the healthcare system, and more accessible, meaning individuals from lower-income communities with less healthcare access or support can still have access to life-saving care. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### The Importance of Non-Invasive Measures\n",
    "Non-invasive measures are used in early detection and often used as a preliminary test before more expensive or invasive tests, such as catheterization, angiography, or various scans. However, if used to detect issues early, it can allow for treatment plans that may not need to involve such tests, and can manage or mitigate the condition without the need for more invasive tests. Common invasive tests like cardiac catheterization, coronary angiography, CT scans, and MRIs can cost thousands to tens of thousands of dollars per procedure. This means that individuals within lower-income communities might not be able to access such tests or treatment needed for late-stage heart disease. Additionally, economically disadvantaged communities often have comparatively poor infrastructure, and resources are stretched thin, making access to these tests and treatments more difficult yet.\n",
    "\n",
    "While non-invasive tests are particularly important for matters of accessibility, they are useful for a number of other reasons regardless of socioeconomic status. In addition to the previously stated importance of early detection, non-invasive measures like the ones gathered in our data pose a much lower (near zero) risk of complication, as opposed to the inherent risk posed by any invasive measure or test. Patient comfort can also be a big factor in ensuring well-being. If patients are hesitant to check on their heart  health because of worries regarding the nature of the measure being used, they are less likely to take a more active role in checking up on their health. This means that they are more likely to test for problems only when they bring about obvious discomfort, thereby often catching the issue too late."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### About the Dataset\n",
    "This dataset was provided by the UC Irvine Machine Learning Repository and contains data from various databases but has more specifically been processed from Cleveland detailing data from 303 patients in the area. A mix of categorical and integer data, the set features information regarding age, blood sugar, heart rate, cholesterol, and other features regarding heart health and general medical tests. The final column in this dataset, referred to in the \"y\" table refers to the presence and severity of a heart disease or absence, measured 0-4, which we later changed to a boolean attribute of either \"yes\" or \"no\" for appearance and efficiency of predicting. Instead of predicting severity, our aim was to predict presence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# importing neccesary libraries and packages\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Reading the CSVs in from the UCI dataset we pulled it from. Thankfully, the UCI Machine Learning Repository had the data processed as pandas data frames. To use this data in CoCalc, we needed to export the dataframes as CSVs and then import the datasets individually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "X = pd.read_csv('X')\n",
    "y = pd.read_csv('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "During our data cleaning, as we were importing the dataset, we noticed that an \"Unnamed: 0\" column appeared in both datasets as part of being converted into CSVs and then being exported. Next, we decided to change the values of the y dataset representing the heart disease status as an indicator of presence or absence. Prior to this as well, we had removed the NA values in various columns and disregarded those rows in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "y.drop(\"Unnamed: 0\", axis = 1, inplace=True)\n",
    "X.drop(\"Unnamed: 0\", axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Explanation of the Column Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As the column names are abbreviated, below is an explanation for each for better understanding.\n",
    "- Age: age of the patient\n",
    "- Sex: sex of the paitent, represented as a 0 or 1 for male or female\n",
    "- CP: chest pain type (1-4) relating to angina pain, non-anginal pain or no chest pain\n",
    "- trestbps: resting blood presure (on admission to the hospital)\n",
    "- chol: cholestrol level measured in mg/dL\n",
    "- fbs: if fasting blood sugar > 120 mg/dL, represented as 1 if yes, and 0 if no\n",
    "- restecg: resting electrocardiographic results (records electrical activity in the heart while at rest, value 0 is normal, while 1-2 is abnormality or possible hypertrophy)\n",
    "- thalach: maximum heart rate achieved\n",
    "- exang: exercise induced angina (or chest pain), yes = 1, no = 0\n",
    "- oldpeak: ST depression induced by exercise relative to resting (a figure related to heart rate and heartbeats)\n",
    "- slope: slope of the peak exercise ST segment, relating to how quick heart rate increases, decreases or flatlines\n",
    "- ca: number of major vessels colored by fluoroscopy (essentially an X-ray movie which shows the passage of blood flow through vessels)\n",
    "- thal: a prediction of blood flow related to the blood disease called thalassemia, an inherited blood disorder where the body does not make enough hemoglobin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The singular column in the \"y\" dataset contains integers 0-4 that are a measurement of how present a heart disease in a person from 1-4 while 0 recognizes an absence. We decided to change the 0s to No's as an absence of heart disease while 1-4 shows up as a Yes showing presence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "changing_presence = {0: \"No\", 1 : \"Yes\", 2 : \"Yes\", 3: \"Yes\", 4: \"Yes\"}\n",
    "\n",
    "y_new = y[\"num\"].replace(changing_presence)\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For the preprocessing for the algorithm, we decided to split our data into training and testing sets with an 80:20 split respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_new, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In order to see how well our algorithm was performing, we used many different metrics such as accuracy, the precision (% of predictions that were true), recall (% of predictions that were correctly identified), and the F1 score which was the average of the precision and the recall. Our algorithm's accuracy was 89% which was quite promising considering how ambivalent it can be when predicting any disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We were then interested in seeing which features were most important when understanding the predictors of heart disease. Using the feature importances function and the argsort function from numpy, we were able to pull the columns from the X dataset which were most influential in making the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#To find which features are important for Random Forest Decision Making\n",
    "importances = clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "indices = np.argsort(importances[::-1])\n",
    "names = [X.columns[i] for i in indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.bar(range(X.shape[1]), importances[indices])\n",
    "plt.xticks(range(X.shape[1]), names, rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Looking at the feature importance, first and foremost, the feature or column that plays the biggest role in the decision making done by our random forest model. \"CP\" meaning more specifically, types of chest pain, was used on a scale of (1-4) as well for different types of chest pain, more specifically known as angina. A symptom of coronary artery diseases, angina is severe chest pain and can often feel like squeezing, pressure or the heaviness of the chest. It makes sense that this column plays such a huge role in the decision making as it is such a common symptom of many heart dieases. Some other notable columns that we found which had importance as a feature included the \"thalach\" column which details the maximum heart rate achieved when under stress or exercise. A non-invasive measure, this is used by medical professionals to discover how fast a patient's heart rate gets to. Although normal to have a high heart rate when exercising, there are certain safe zones for different age groups. The final major feature is the \"oldpeak\" column. This column relates to the ST depression induced by exercise relative to rest. We were not familiar with this term so after doing further research we found that ST depression refers to the drop below resting heart rate when doing exercise related testing and can often be seen as a symptom of myocardial ischemia or when the heart does not receive enough oxygen-rich blood. Some other notable features include age, cholesterol and fluoroscopies, which see how the blood flows through the arteries of different blood vessels. Looking at our top 3 features, it is clear that non-invasive methods such as measuring chest pain, max heart rate when exercising and ST depression are good predictors of heart disease and can be used in the diagnosis of heart diseases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "tree_index  = 0\n",
    "first_tree = clf.estimators_[tree_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plot_tree(first_tree ,feature_names = X.columns, class_names = [\"No\", \"Yes\"], filled = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "When looking at our random forest model, we were also particularly interested in how one of the many decision trees would work when applying many of these features to vote on a prediction. Using the plot tree function in sklearn, we were able to do so in plotting the first decision tree from our model. As can be seen, there are many decisions and features that are undertaken for the prediction of absence or presence of a heart disease. Some interesting decisions we found was the last branch and leaves on the left which takes into account whether or not the cholesterol is less than or equal to 245.5 mg/dL. A borderline high cholesterol level, the prediction that it made was that it was less likely for a heart disease to occur which we found very intriguing. Another interesting list of branches and leaves we found were the branches related to blood pressure and that having a high resting blood pressure after being admitted into the hospital was a good predictor of having a heart disease. Although this is only one of many decision trees, methods like these can assist medical professionals in using non-invasive measures such as testing blood pressure, finding out the heart rate and taking their age into account to help best predict the presence of heart disease in their paitents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='OrRd', xticklabels=np.sort(y_new.unique()), yticklabels=np.sort(y_new.unique()))\n",
    "plt.xlabel(\"True Value\")\n",
    "plt.ylabel(\"Predicted Value\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The confusion matrix shows the efficiency of our random forest model. Specifically, along with a heatmap to show density, it shows the number of true and false negatives and positives obtained by using the model on the testing portion of the data after being trained on the bulk of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "falseposrate = 3/29\n",
    "falsenegrate = 4/32\n",
    "print(f'False positive rate: {falseposrate:.2f}')\n",
    "print(f'False negative rate: {falsenegrate:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "With a false positive rate of 10% and a false negative rate of 12%, we can say that our model is quite accurate in detecting the absence or presence of heart disease based solely off of non-invasive measures. In other words, looking at the confusion matrix, if 61 patients walked into a clinic and the measurements found in our data were taken, using our model, 54 of the patients would have received a correct diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Conclusion\n",
    "By taking a data-driven approach to explore factors contributing to heart disease, we saw that non-invasive measures can reliably predict the presence or absence of heart disease in patients via machine learning models. Non-invasive testing serves a crucial role in the critically important early detection of heart disease, which is the single biggest factor in effectively managing and preventing heart disease. These non-invasive measures are particularly important in economically disadvantaged communities because they make care for the single biggest killer in the U.S. more accessible and put less strain on already thinly-spread healthcare infrastructure, but also important for the broader population regardless of socioeconomic status, due to the low risk and ease of access at the individual level. This project aligns with the broader public health objective of making healthcare more affordable and accessible, and ultimately increasing societal well-being and decreasing heart disease-related mortality while emphasizing the critical importance of early detection for the management and prevention of heart disease via non-invasive measures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- Link to learn more about ST depression: https://www.ncbi.nlm.nih.gov/books/NBK459364/#:~:text=ST%20depression%20occurs%20when%20the,and%20medications%20such%20as%20digitalis.\n",
    "- UCI Machine Learning Repository: https://archive.ics.uci.edu/dataset/45/heart+disease\n",
    "- Angina: https://my.clevelandclinic.org/health/diseases/21489-angina \n",
    "- Data Regarding Heart Disease Detection Using Non-Invasive Measures: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8885242/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel",
    "--HistoryManager.enabled=False",
    "--matplotlib=inline",
    "-c",
    "%config InlineBackend.figure_formats = set(['retina'])\nimport matplotlib; matplotlib.rcParams['figure.figsize'] = (12, 7)",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (system-wide)",
   "env": {
   },
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}